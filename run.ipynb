{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb96c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957dc8aa",
   "metadata": {},
   "source": [
    "## load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e05002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/chaoqiy2/data/MNIST/Spatio-temporal/\"\n",
    "claim_tensor = torch.Tensor(\n",
    "    pickle.load(open(os.path.join(root, \"claim_tensor.pkl\"), \"rb\"))\n",
    ")\n",
    "county_tensor = torch.Tensor(\n",
    "    pickle.load(open(os.path.join(root, \"county_tensor.pkl\"), \"rb\"))\n",
    ")\n",
    "covid_tensor = torch.Tensor(\n",
    "    pickle.load(open(os.path.join(root, \"covid_tensor.pkl\"), \"rb\"))\n",
    ")\n",
    "distance_mat = torch.Tensor(\n",
    "    pickle.load(open(os.path.join(root, \"distance_mat.pkl\"), \"rb\"))\n",
    ")\n",
    "hos_tensor = torch.Tensor(pickle.load(open(os.path.join(root, \"hos_tensor.pkl\"), \"rb\")))\n",
    "mob_mat = torch.Tensor(pickle.load(open(os.path.join(root, \"mob_mat.pkl\"), \"rb\")))\n",
    "vac_tensor = torch.Tensor(pickle.load(open(os.path.join(root, \"vac_tensor.pkl\"), \"rb\")))\n",
    "\n",
    "feat_name = pickle.load(open(os.path.join(root, \"feat_name.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a86dfac",
   "metadata": {},
   "source": [
    "## combine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40d28f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2334, 14]) torch.Size([2334, 639, 59]) torch.Size([2334, 2334]) torch.Size([2334, 2334])\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "demographs = county_tensor\n",
    "cty_day_feat = torch.cat(\n",
    "    [claim_tensor, covid_tensor.unsqueeze(-1), hos_tensor, vac_tensor], dim=-1\n",
    ").to(device)\n",
    "graph1 = distance_mat.to(device)\n",
    "graph2 = mob_mat.to(device)\n",
    "\n",
    "print(demographs.shape, cty_day_feat.shape, graph1.shape, graph2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517e3995",
   "metadata": {},
   "source": [
    "## optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c69459e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def optimize(A, B, D, reg=1e-8):\n",
    "    u = torch.linalg.solve(A + reg * D, B)\n",
    "    return u\n",
    "\n",
    "def CPD(T, R, graph, Lambda, iteration=50, device=\"cuda:0\", A1=None, A2=None, A3=None):\n",
    "    # preparation\n",
    "    loss_list = []\n",
    "    d1, d2, d3 = T.shape\n",
    "\n",
    "    if A1 is None:\n",
    "        A1 = torch.randn(d1, R).to(device)\n",
    "        A2 = torch.randn(d2, R).to(device)\n",
    "        A3 = torch.randn(d3, R).to(device)\n",
    "    \n",
    "    D = torch.eye(R).to(device)\n",
    "    \n",
    "    # ALS \n",
    "    tic = time.time()\n",
    "    for i in range(iteration):\n",
    "\n",
    "        # sub-iteration\n",
    "        if i > 10:\n",
    "            A1_ = A1.clone()\n",
    "            loss = []\n",
    "            for j in range(1):\n",
    "                A1 = optimize((A3.T@A3)*(A2.T@A2), torch.einsum('ijk,jr,kr->ri',T,A2,A3) - \\\n",
    "                              Lambda * A1.T@graph, D).T\n",
    "                loss.append((torch.norm(A1 - A1_) / torch.norm(A1_)).item())\n",
    "                A1_ = A1.clone()\n",
    "#             print (\"A precision:\", loss)\n",
    "        else:\n",
    "            A1 = optimize((A3.T@A3)*(A2.T@A2), torch.einsum('ijk,jr,kr->ri',T,A2,A3), D).T\n",
    "            A2 = optimize((A1.T@A1)*(A3.T@A3), torch.einsum('ijk,ir,kr->rj',T,A1,A3), D).T\n",
    "            A3 = optimize((A1.T@A1)*(A2.T@A2), torch.einsum('ijk,ir,jr->rk',T,A1,A2), D).T\n",
    "\n",
    "        # loss \n",
    "        rec = torch.einsum('ir,jr,kr->ijk',A1,A2,A3)\n",
    "        loss1 = torch.norm(rec - T) / torch.norm(T)\n",
    "        loss2 = torch.trace(A1.T@graph@A1)\n",
    "        if i % 10 == 9:\n",
    "            print ('{}/{}'.format(i, iteration), 'loss1:', loss1.item(), 'loss2:', loss2.item(), 'time span:', time.time() - tic)\n",
    "\n",
    "        # collect loss\n",
    "        tic = time.time() \n",
    "        loss_list.append((loss1+loss2).item())\n",
    "\n",
    "    return A1, A2, A3, loss_list\n",
    "\n",
    "\n",
    "def get_laplacian(A, normalized=True):\n",
    "    # -------------------------------\n",
    "    # calculate the laplacian\n",
    "    A = torch.Tensor(A)\n",
    "    D = A.sum(axis=1)\n",
    "    if normalized:\n",
    "        D_rev = torch.diag(D ** (-0.5))\n",
    "        L = torch.eye(len(D)) - D_rev @ A @ D_rev\n",
    "    else:\n",
    "        L = torch.diag(D) - A\n",
    "    L = L.to(device)\n",
    "    # ---------------------------------\n",
    "    return L\n",
    "\n",
    "dis_laplacian = get_laplacian(distance_mat)\n",
    "mob_laplacian = get_laplacian(mob_mat)\n",
    "graph = - 1e-1 * dis_laplacian + 1 * mob_laplacian "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b331186a",
   "metadata": {},
   "source": [
    "## normalize the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "620cc9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = torch.mean(cty_day_feat, dim=(0,1), keepdim=True)\n",
    "STD = torch.std(cty_day_feat, dim=(0,1), keepdim=True)\n",
    "new_T = cty_day_feat / MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e071ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1 = torch.randn(2334, 5)\n",
    "# A2 = torch.randn(639, 5)\n",
    "# A3 = torch.randn(59, 5)\n",
    "# T = torch.einsum(\"ir,jr,kr->ijk\",A1,A2,A3)\n",
    "# MEAN = torch.mean(T, dim=(0,1), keepdim=True)\n",
    "# STD = torch.std(T, dim=(0,1), keepdim=True)\n",
    "# new_T = ((T - MEAN) / STD).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "06ccf87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/50 loss1: 0.05293762683868408 loss2: 814290.0 time span: 0.02203845977783203\n",
      "19/50 loss1: 0.052398793399333954 loss2: 835749.625 time span: 0.007366180419921875\n",
      "29/50 loss1: 0.052398793399333954 loss2: 835749.625 time span: 0.0073757171630859375\n",
      "39/50 loss1: 0.052398793399333954 loss2: 835749.625 time span: 0.007353782653808594\n",
      "49/50 loss1: 0.052398793399333954 loss2: 835749.625 time span: 0.0073697566986083984\n"
     ]
    }
   ],
   "source": [
    "A1, A2, A3, loss_list = CPD(cty_day_feat, graph=graph, Lambda=1e3, R=5, iteration=50, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2437c8e",
   "metadata": {},
   "source": [
    "## dump out the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c7b5bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "pickle.dump(A1.cpu().numpy(), open(\"decomp.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "17c83468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34903/2022746450.py:1: RuntimeWarning: invalid value encountered in log\n",
      "  plt.hist(np.log(-A1[:, 1].cpu().numpy()))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  3.,   6.,  53., 242., 338., 525., 521., 284.,  91.,  13.]),\n",
       " array([-11.691273 , -10.084544 ,  -8.477816 ,  -6.871086 ,  -5.2643576,\n",
       "         -3.6576288,  -2.0509   ,  -0.4441712,   1.1625576,   2.7692864,\n",
       "          4.376015 ], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log(-A1[:, 1].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2503f5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.366516072160513e-06,\n",
       " 4.171941291326946e-05,\n",
       " 0.00020803255002531403,\n",
       " 0.0010373498906893798,\n",
       " 0.0051727149132769325,\n",
       " 0.025793602059426626,\n",
       " 0.1286190942965734,\n",
       " 0.641355611347234,\n",
       " 3.1981022915471025,\n",
       " 15.947249990865679,\n",
       " 79.52051192370948]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in np.exp([-11.691273 , -10.084544 ,  -8.477816 ,  -6.871086 ,  -5.2643576,\n",
    "         -3.6576288,  -2.0509   ,  -0.4441712,   1.1625576,   2.7692864,\n",
    "          4.376015 ])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2319ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
